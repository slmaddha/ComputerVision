{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://medium.com/@fernandopalominocobo/mastering-u-net-a-step-by-step-guide-to-segmentation-from-scratch-with-pytorch-6a17c5916114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![unet-arch](../assets/unet_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "from math import atan2, cos, sin, sqrt, pi, log\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from numpy import linalg as LA\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double Convolutions with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # two convolutions with 3x3 kernel\n",
    "        self.conv_op = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.conv_op(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling involves using double convolutions followed by max pooling\n",
    "- We also save the convolutioned tensore before max pooling to allow for skip connections between low and high level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        down = self.double_conv(x)\n",
    "        p = self.max_pool(down)\n",
    "        \n",
    "        return down, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling involves deconvolution followed by the double convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "        \n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # decoder\n",
    "        self.down_conv_1 = Downsample(in_channels, out_channels=64)\n",
    "        self.down_conv_2 = Downsample(in_channels=64, out_channels=128)\n",
    "        self.down_conv_3 = Downsample(in_channels=128, out_channels=256)\n",
    "        self.down_conv_4 = Downsample(in_channels=256, out_channels=512)\n",
    "        \n",
    "        # bottleneck\n",
    "        self.bottle_neck = DoubleConv(in_channels=512, out_channels=1024)\n",
    "        \n",
    "        # encoder\n",
    "        self.up_conv_1 = Upsample(in_channels=1024, out_channels=512)\n",
    "        self.up_conv_2 = Upsample(in_channels=512, out_channels=256)\n",
    "        self.up_conv_3 = Upsample(in_channels=256, out_channels=128)\n",
    "        self.up_conv_4 = Upsample(in_channels=128, out_channels=64)\n",
    "        \n",
    "        # segmentation map\n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # decoder\n",
    "        down_1, p1 = self.down_conv_1(x)\n",
    "        down_2, p2 = self.down_conv_2(p1)\n",
    "        down_3, p3 = self.down_conv_3(p2)\n",
    "        down_4, p4 = self.down_conv_4(p3)\n",
    "        \n",
    "        # bottleneck\n",
    "        b = self.bottle_neck(p4)\n",
    "        \n",
    "        # encoder\n",
    "        up_1 = self.up_conv_1(b, down_4)\n",
    "        up_2 = self.up_conv_2(up_1, down_3)\n",
    "        up_3 = self.up_conv_3(up_2, down_2)\n",
    "        up_4 = self.up_conv_4(up_3, down_1)\n",
    "        \n",
    "        # segmentation map\n",
    "        out = self.out(up_4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test with dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.rand((1, 3, 512, 512))\n",
    "model = UNet(3, 10) # rgb 3 channel / 10 classes\n",
    "output = model(input_image)\n",
    "print(output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
